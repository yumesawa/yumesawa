{"meta":{"title":"YUME","subtitle":null,"description":null,"author":"梦沢","url":"http://yoursite.com","root":"/"},"pages":[{"title":"逮到你了！","date":"2019-12-27T02:41:27.926Z","updated":"2019-12-27T02:41:27.926Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"小妖怪们","date":"2019-12-27T12:54:56.830Z","updated":"2019-12-27T12:54:56.830Z","comments":true,"path":"friends/index.html","permalink":"http://yoursite.com/friends/index.html","excerpt":"","text":"欢迎交换友链呀~ (๑╹◡╹)ﾉ”””需要的小可爱可以在下方留言哦必需提供：名称、头像连接、博客连接、至少一个标签非必须：分组举个栗子： 1234名称：yume头像连接：http://lc-t0sXLoMn.cn-n1.lcfile.com/720191227193341.jpg博客连接：https://yumesawa.github.io/标签：Python"},{"title":"归档","date":"2019-12-26T12:34:45.575Z","updated":"2019-12-26T12:34:45.575Z","comments":true,"path":"blog/archives/index.html","permalink":"http://yoursite.com/blog/archives/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2019-12-26T12:03:38.897Z","updated":"2019-12-26T12:03:38.897Z","comments":true,"path":"blog/tags/index.html","permalink":"http://yoursite.com/blog/tags/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2019-11-14T12:14:11.836Z","updated":"2019-11-14T12:14:11.835Z","comments":true,"path":"blog/categories/index.html","permalink":"http://yoursite.com/blog/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"大文件上传与下载解决方案","slug":"大文件上传与下载解决方案","date":"2019-11-25T16:00:00.000Z","updated":"2019-12-27T12:29:42.052Z","comments":true,"path":"2019/11/26/大文件上传与下载解决方案/","link":"","permalink":"http://yoursite.com/2019/11/26/%E5%A4%A7%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E4%B8%8E%E4%B8%8B%E8%BD%BD%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","excerpt":"","text":"分片上传基于 simple-uploader.js的vue插件vue-simple-uploader 实现分片上传。 分片上传，就是将所要上传的文件，按照一定的大小，将整个文件分隔成多个数据块（我们称之为Part）来进行分别上传，上传完之后再由服务端对所有上传的文件进行汇总整合成原始的文件。分片上传不仅可以避免因网络环境不好导致的一直需要从文件起始位置还是上传的问题，还能使用多线程对不同分块数据进行并发发送，提高发送效率，降低发送时间。 分片上传的整个流程大致如下： 将需要上传的文件按照一定的分割规则，分割成相同大小的数据块； 初始化一个分片上传任务，返回本次分片上传唯一标识； 按照一定的策略（串行或并行）发送各个分片数据块； 发送完成后，服务端根据判断数据上传是否完整，如果完整，则进行数据块合成得到原始文件。 在整个数据上传的过程中当然还涉及数据的签名校验，防止数据被恶意篡改。整个上传流程图如下所示 ： 关于vue-simple-uploader 在日常开发中经常会遇到文件上传的需求，vue-simple-uploader 就是一个基于 simple-uploader.js 和 Vue 结合做的一个上传组件，自带 UI，可覆盖、自定义； 其主要特点就是： 支持文件、多文件、文件夹上传- 支持拖拽文件、文件夹上传 统一对待文件和文件夹，方便操作管理 可暂停、继续上传 错误处理 支持“快传”，通过文件判断服务端是否已存在从而实现“快传” 上传队列管理，支持最大并发上传 分块上传 支持进度、预估剩余时间、出错自动重试、重传等操作 安装通过npm安装：npm install vue-simple-uploader --save即可。 使用在main.js中初始化123456789101112import Vue from 'vue'import uploader from 'vue-simple-uploader'import App from './App.vue'Vue.use(uploader)/* eslint-disable no-new */new Vue(&#123; render(createElement) &#123; return createElement(App) &#125;&#125;).$mount('#app') 新建一个vue组件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;template&gt; &lt;uploader :options=&quot;options&quot; class=&quot;uploader-example&quot;&gt; &lt;uploader-unsupport&gt;&lt;/uploader-unsupport&gt; &lt;uploader-drop&gt; &lt;p&gt;Drop files here to upload or&lt;/p&gt; &lt;uploader-btn&gt;select files&lt;/uploader-btn&gt; &lt;uploader-btn :attrs=&quot;attrs&quot;&gt;select images&lt;/uploader-btn&gt; &lt;uploader-btn :directory=&quot;true&quot;&gt;select folder&lt;/uploader-btn&gt; &lt;/uploader-drop&gt; &lt;uploader-list&gt;&lt;/uploader-list&gt; &lt;/uploader&gt;&lt;/template&gt;&lt;script&gt;export default &#123; name:&apos;Upload&apos;, data () &#123; return &#123; options: &#123; // https://github.com/simple-uploader/Uploader/tree/develop/samples/Node.js target: this.$api+&apos;api/user/upload/&apos;, testChunks: false, chunkSize: &apos;2048000&apos; &#125;, attrs: &#123; accept: &apos;image/*&apos; &#125;, &#125; &#125;,&#125;&lt;/script&gt;&lt;style&gt;.uploader-example &#123; width: 880px; padding: 15px; margin: 40px auto 0; font-size: 12px; box-shadow: 0 0 10px rgba(0, 0, 0, .4);&#125;.uploader-example .uploader-btn &#123; margin-right: 4px;&#125;.uploader-example .uploader-list &#123; max-height: 440px; overflow: auto; overflow-x: hidden; overflow-y: auto;&#125;&lt;/style&gt; 后端思路：为每个分片创建一个新的临时文件来保存其内容；待全部分片上传完毕后，再按顺序读取所有临时文件的内容，将数据写入新文件中。 在前端给我们的中不止含有文件，还有如下参数： chunkNumber: 当前块的次序，第一个块是 1，注意不是从 0 开始的。 totalChunks: 文件被分成块的总数。 chunkSize: 分块大小，根据 totalSize 和这个值你就可以计算出总共的块数。注意最后一块的大小可能会比这个要大。 currentChunkSize: 当前块的大小，实际大小。 totalSize: 文件总大小。 identifier: 这个就是每个文件的唯一标示。 filename: 文件名。 relativePath: 文件夹上传的时候文件的相对路径属性。 我们可以根据文件的唯一标识+当前块数来命名保存一个临时文件，然后进行拼接。 我们在保存临时文件时，由于vue给我们发过来的是异步请求，本来要求请求马上出现,是异步会导致后面突然再执行。 这时会报一个：self._sock.sendall(b) ConnectionAbortedError: [WinError 10053] 您的主机中的软件中止了一个已建立的连接。的错误 有两种解决方案： 在ajax进行异步提交时，将async 改为 false 即可，但是由于vue给我们发的是axios请求，所以并不适用。 123456789$.ajax(&#123; type : \"post\", url : \"**************\", data : data, async : false, success : function(data)&#123; alert(data) &#125; &#125;); 所以我们依赖第二种方案： 找到你python/lib/socketserver.py文件775行，修改SocketWriter类的write方法，具体如下： 1234567def write(self, b): try: self._sock.sendall(b) except Exception as e: self._sock.close() with memoryview(b) as view: return view.nbytes 这时临时文件已经进行保存，全部保存成功后，vue-simple-uploader 会给我们一个回调，我们可以在vue中得到这个回调 12345678910&lt;uploader :options=&quot;options&quot; class=&quot;uploader-example&quot; @file-success=&quot;fileSuccess&quot;&gt; #得到文件上传成功指定一个函数方法 &lt;uploader-unsupport&gt;&lt;/uploader-unsupport&gt; &lt;uploader-drop&gt; &lt;p&gt;Drop files here to upload or&lt;/p&gt; &lt;uploader-btn v-on:finish=&quot;fileSuccess&quot;&gt;select files&lt;/uploader-btn&gt; &lt;uploader-btn :attrs=&quot;attrs&quot;&gt;select images&lt;/uploader-btn&gt; &lt;uploader-btn :directory=&quot;true&quot;&gt;select folder&lt;/uploader-btn&gt; &lt;/uploader-drop&gt; &lt;uploader-list&gt;&lt;/uploader-list&gt;&lt;/uploader&gt; 此时这个函数会有如下参数： fileSuccess(rootFile, file, message, chunk)一个文件上传成功事件 第一个参数rootFile就是成功上传的文件所属的根Uploader.File对象，它应该包含或者等于成功上传文件； 第二个参数file就是当前成功的Uploader.File对象本身； 第三个参数就是message就是服务端响应内容，永远都是字符串； 第四个参数chunk就是Uploader.Chunk实例，它就是该文件的最后一个块实例，如果你想得到请求响应码的话，chunk.xhr.status 就是。 我们可以根据message返回的状态码来判断文件是否上传成功（注意转JSON），从而发起一个axios请求，进行文件拼接，此时临时文件上传与文件拼接是原子性的。我们可以把上传成功文件的唯一标识以及文件名称发给后端 我们可以在后端以wb方式打开一个文件，此时的文件就是前端发给我们的文件名，然后根据文件唯一标识去遍历临时文件，依次写入，然后删除临时文件 代码如下： 12345678910111213chunk=1 with open('static/media/'+request.data['filename'],'wb') as tar_file: while True: try: filename = 'static/media/'+request.data['uniquefile']+str(chunk) tem_file=open(filename,'rb') tar_file.write(tem_file.read()) tem_file.close() except IOError: break chunk+=1 os.remove(filename) return Response(&#123;'data':200&#125;) 此时一个大文件的上传并写入操作以及完成了！ 附上git：https://gitee.com/likezx/upload_vue.git 断点续传为了避免客户端在下载之后的进度数据被删除而导致重新开始从头下载的问题，服务端也可以提供相应的接口便于客户端对已经下载的分片数据进行查询，从而使客户端知道已经下载的分片数据，从而从下一个分片数据开始继续下载。 所谓断点续传，前提是上传文件为大文件，如果文件较小，则体现不出断点续传的优势。 断点续传大文件的优势： 文件上传过程中上传了一半，网络中断，再次上传可以从上次中断处开始上传，节省带宽和上传时间。 由于断点续传需要验证文件的hash，可以避免相同文件多次上传，节约服务器存储空间，节约用户操作时间，加上友好提示，可以提高用户的体验度。 要实现HTTP断点续传必须要简单了解以下几个报文： Accept-Ranges： 告诉客户端(浏览器..)服务器端支持断点续传 服务器端返回 Range：客户端告诉服务器端从指定的的位置/范围(这里值字节数)下载资源 客户端发出 Content-Range： 服务器端告诉客户端响应的数据信息，在整个返回体中本部分的字节位置 服务器端返回 ETag： 资源标识 非必须 服务器端返回 Last-Modified： 资源最后一次更新的时间 非必须 服务器端返回 Range 的范围格式： 表示0-499个字节范围：Range: bytes=0-499 表示最后500个字节范围：Range: bytes=-500 表示500字节开始到结束范围：Range: bytes=500- 表示第一个和最后一个字节：Range: bytes=0-0,-1 表示同时指定几个范围：Range: bytes=500-600,601-999 Content-Range 的数据格式： Content-Range: bytes 0-499/22036 ：表示返回0-499字节范围数据 资源一共22036个字节 原理： 客户端发起请求 设置Range指定开始字节数或结束字节数 如果是从0开始也可以不用设置。 服务器端检查到客户端Range头 解析开始字节数以及结束字节数 并返回报文头 Accept-Ranges表示支持断点续传，Content-Range记录该次向客户端写入流的位置信息，然后再写入流到客户端。 服务端可以使用ETag Last-Modified 标记一下资源是否被修改。作一些验证工作，如果验证不通过则返回错误，非必须项。 实现方式： 功能基于django.views.static.serve实现，实现的关键点是： response中增加’Content-Range’、’Cache-Control’的参数 根据不同的情况为response设置不同的status 根据HTTP_RANGE对读取文件时的起始位置进行设置 视图函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 下载断点续传class DownlaodFile(APIView): def get(self,request, md5): # 需要get方式传来一个文件的md5值 file = models.File.objects.filter(md5=md5).first() # 根据该md5值到数据库中查找文件 if not file: raise Http404 statobj = os.stat(file.address) ''' print(statobj)后得到： os.stat_result(st_mode=33188, st_ino=1061429, st_dev=64769, st_nlink=1, st_uid=0, st_gid=0, st_size=454004, st_atime=1577018223, st_mtime=1572833320, st_ctime=1572833320) ''' # 判断下载过程中文件是否被修改过 if not was_modified_since( request.META.get('HTTP_IF_MODIFIED_SINCE'), statobj.st_mtime, statobj.st_size ): return HttpResponseNotModified() # 获取文件的content_type content_type, encoding = mimetypes.guess_type(file.address) content_type = content_type or 'application/octet-stream' # 文件起点位置 start_bytes = re.search( r'bytes=(\\d+)-', request.META.get('HTTP_RANGE', ''), re.S ) start_bytes = int(start_bytes.group(1)) if start_bytes else 0 # 移动文件至上次下载位置 the_file = open(file.address, 'rb') the_file.seek(start_bytes, os.SEEK_SET) ''' status=200表示下载开始，status=206表示下载暂停后继续，为了兼容火狐浏览器而区分两种状态 关于django的response对象，参考：https://www.cnblogs.com/scolia/p/5635546.html 关于response的状态码，参考：https://www.cnblogs.com/DeasonGuan/articles/Hanami.html FileResponse默认block_size = 4096，因此迭代器每次读取4KB数据 ''' response = FileResponse( the_file, content_type = file.mimeType or 'application/octet-stream', status = 206 if start_bytes &gt; 0 else 200 ) # 文件修改时间 response['Last-Modified'] = http_date(statobj.st_mtime) # 这里'Content-Length'表示剩余待传输的文件字节长度 if stat.S_ISREG(statobj.st_mode): response['Content-Length'] = statobj.st_size - start_bytes response['Content-Range'] = 'bytes %s-%s/%s' % ( start_bytes, # 起点 statobj.st_size - 1, statobj.st_size ) response['Cache-Control'] = 'no-cache, no-store, must-revalidate' return response 例子：https://gitee.com/yumesawa/project.git","categories":[{"name":"业务场景","slug":"业务场景","permalink":"http://yoursite.com/categories/%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF/"}],"tags":[{"name":"Django&Vue","slug":"Django-Vue","permalink":"http://yoursite.com/tags/Django-Vue/"}]},{"title":"Nginx防盗链配置","slug":"Nginx防盗链配置","date":"2019-09-24T16:00:00.000Z","updated":"2019-12-27T12:41:51.274Z","comments":true,"path":"2019/09/25/Nginx防盗链配置/","link":"","permalink":"http://yoursite.com/2019/09/25/Nginx%E9%98%B2%E7%9B%97%E9%93%BE%E9%85%8D%E7%BD%AE/","excerpt":"","text":"Nginx防盗链配置案例配置防盗链的含义是网站内容本身不在自己公司的服务器上，而通过技术手段，直接在调用其他公司的服务器网站数据，而向最终用户提供此内容。 一些小网站盗链高访问量网站的音乐、图片、软件的链接，然后放置在自己的网站中，通过这种方法盗取高访问量网站的空间和流量。 网站每天访问量很大，而且占用了很多不必要的带宽，浪费资源，所以必须采取一些限制措施。 防盗链其实就是采用服务器端编程技术，通过URL过滤、主机名等实现的防止盗链的软件。 例如http://www.jfedu.net/linux/页面，如果没有配置防盗链，别人就能轻而易举的在其的网站上引用该页面。 Nginx防盗链配置代码如下：12345678910111213141516server &#123; listen 80； server_name jfedu.net www.jfedu.net； location / &#123; root html/b； index index.html index.htm； &#125; location ~* \\.(gif|jpg|png|swf|flv)$ &#123; valid_referers none blocked jfedu.net *.jfedu.net； root html/b； if ($invalid_referer) &#123; #rewrite ^/ http://www.jfedu.net/403.html； return 403； &#125; &#125;&#125; Nginx防盗链参数详解： valid_referers表示可用的referers设置 none 表示没有referers，直接通过浏览器或者其他工具访问。 blocked表示有referers，但是被代理服务器或者防火墙隐藏； jfedu.net 表示通过jfedu.net访问的referers； *.jfedu.net 表示通过*.jfedu.net访问的referers *表示任意host主机。 除了以上方法，按照如下方法设置也可以实现防盗链：1234location ~* \\.(gif|jpg|png|swf|flv)$if ($host !=’*.jfedu.net’) &#123; return 403；&#125;","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Nginx下载安装","slug":"Nginx下载安装","date":"2019-06-10T16:00:00.000Z","updated":"2019-12-27T12:41:32.518Z","comments":true,"path":"2019/06/11/Nginx下载安装/","link":"","permalink":"http://yoursite.com/2019/06/11/Nginx%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85/","excerpt":"","text":"下载Nginx安装包12wget https://nginx.org/download/nginx-1.16.1.tar.gz# 此时下载的是官方发布的稳定版 解压1tar -zxvf nginx-1.16.1.tar.gz # zxvf解压gz属性的压缩包 进入nginx目录1cd nginx-1.16.1 配置1./configure --prefix=/usr/local/nginx make12makemake install 测试是否安装成功12cd到刚才配置的安装目录/usr/loca/nginx/./sbin/nginx -t 开启80端口：12firewall-cmd --add-port=80/tcp --permanent--permanent #永久生效，没有此参数重启后失效 重启防火墙1systemctl restart firewalld 启动nginx12cd /usr/local/nginx/sbin./nginx //启动nginx 配置nginx开机自启动1vim /etc/rc.d/rc.local 卸载1yum remove nginx","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Redis主从复制","slug":"Redis主从复制","date":"2019-05-11T16:00:00.000Z","updated":"2019-12-27T12:42:58.408Z","comments":true,"path":"2019/05/12/Redis主从复制/","link":"","permalink":"http://yoursite.com/2019/05/12/Redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","excerpt":"","text":"Reids主从 ​ 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。 ​ 默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。 主从复制的作用 数据冗余： 主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复： 当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡： 在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石： 主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 主从拓扑结构​ 一主一从： 用于主节点故障转移从节点，当主节点的“写”命令并发高且需要持久化，可以只在从节点开启AOF（主节点不需要），这样即保证了数据的安全性，也避免持久化对主节点的影响。 ​ 一主多从： 这一结构主要针对“读”较多的场景，“读”由多个从节点来分担，但节点越多，主节点同步到多节点的次数也越多，影响带宽，也加重主节点的稳定。 ​ 树状主从: 这一结构是对一主多从的补充，主节点只推送一次数据到slave1和slave2，再由从slave2推送到slave3和 slave4，减轻主节点推送的压力。 主从复制的实现原理主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段； 连接建立阶段step1：保存主节点信息​ 从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。 ​ slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。 step2：建立socket连接​ 从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。 如果连接成功： ​ 从节点： 为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。 ​ 主节点： 接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。 step3：发送ping命令​ 从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。 从节点发送ping命令后，可能出现3种情况： 返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。 超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。 返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。 step4：身份验证如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。 从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。 如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。 step5：发送从节点端口信息身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。 数据同步阶段主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。 具体执行的方式是：从节点向主节点发送psync命令，开始同步。 数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制。 在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。 命令传播阶段​ 数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。 ​ 在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。 PS： ​ 延迟与不一致： 命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。 ​ repl-disable-tcp-nodelay no： 该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。 【数据同步阶段】全量复制和部分复制在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制； 在Redis2.8以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。 部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。 全量复制Redis通过psync命令进行全量复制的过程如下： 从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制； 主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令。 主节点的bgsave执行完成后，将RDB文件发送给从节点；从节点首先清除自己的旧数据，然后载入接收的RDB文件，将数据库状态更新至主节点执行bgsave时的数据库状态。 主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态。 如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态。 通过全量复制的过程可以看出，全量复制是非常重型的操作： 主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的； 主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗。 从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗。 部分复制​ 由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。 ​ 部分复制的实现，依赖于三个重要的概念：复制偏移量，复制积压缓冲区，服务器运行ID offset 复制偏移量​ 在主从复制的Master(主节点)和Slave(从节点)双方都会各自维持一个offset，代表的是主节点向从节点传递的字节数；Master成功发送N个字节的命令后会将Master的offset加上N，Slave在接收到N个字节命令后同样会将Slave的offset增加N。Master和Slave如果状态是一致的那么它的的offset也应该是一致的。 ​ offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。 复制积压缓冲区 复制积压缓冲区是由Master(主节点)维护的一个固定长度的FIFO队列(先进先出)，默认大小1MB；当主节点开始有从节点时创建，它的作用是缓存已经传播出去的命令。当Master进行命令传播时，不仅将命令发送给所有Slave，还会将命令写入到复制积压缓冲区里面。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。 ​ 除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。 ​ 由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。 从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制： 如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制； 如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。 runid 服务器运行ID​ 每个Redis服务器(无论主从)在启动时都会自动生成一个表明自己身份的随机ID(每次启动都不一样)，由40个随机的十六进制字符组成。在PSYNC中发送的这个ID是指之前连接的Master的ID，如果没保存这个ID，PSYNC命令会使用 ”PSYNC ? -1” 这种形式发送给Master，表示需要全量复制。 ​ 每个Redis节点，在启动时都会自动生成一个随机ID，由40个随机的十六进制字符组成； runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid。 ​ 主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点； 主节点根据runid判断能否进行部分复制： 如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)； 如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。 PSYNC命令 Redis在2.8版本提供了PSYNC命令来带代替SYNC命令，为Redis主从复制提供了部分复制的能力。 PSYNC命令格式123PSYNC &lt;runid&gt; &lt;offset&gt;# runid:主服务器ID# offset:从服务器最后接收命令的偏移量 PSYNC执行过程中比较重要的概念有3个：runid、offset（复制偏移量）以及复制积压缓冲区。 psync命令的执行 首先从节点根据当前状态，决定如何调用psync命令： 如果从节点之前未执行过slaveof或最近执行了slaveof no one，则从节点发送命令为psync ? -1，向主节点请求全量复制； 如果从节点之前执行了 slaveof，则发送命令为 psync ，其中 runid 为上次复制的主节点的 runid ，offset 为上次复制截止时从节点保存的复制偏移量。 主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制： 如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制； 如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可； 如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复 +FULLRESYNC ，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。 【命令传播阶段】心跳机制在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。 主-&gt;从：PING每隔指定的时间，主节点会向从节点发送PING命令，这个PING命令的作用，主要是为了让从节点进行超时判断。 PING发送的频率由 repl-ping-slave-period 参数控制，单位是秒，默认值是10s。 从-&gt;主：REPLCONF ACK在命令传播阶段， 从节点会向主节点发送REPLCONF ACK命令， 频率是每秒1次； 命令格式为： 1REPLCONF ACK &#123;offset&#125; # offset指从节点保存的复制偏移量。 REPLCONF ACK命令的作用包括： 实时监测主从节点网络状态： 该命令会被主节点用于复制超时的判断。此外，在主节点中使用info Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1。 检测命令丢失： 从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。 注意：offset和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。 辅助保证从节点的数量和延迟： Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值。 开启主从复制从节点开启主从复制，有3种方式： 配置文件：在从服务器的配置文件中加入：slaveof 启动命令：redis-server启动命令后加入： –slaveof 客户端命令：Redis服务器启动后，直接通过客户端执行命令：slaveof ，则该Redis实例成为从节点。 修改配置文件方法：1. 配置从服务配置文件redis.conf1234567slaveof 192.168.1.9 6379 #添加属于某台主机的从 服务masterauth 123456 #从服务连接主服的密码（访问主服务器的密码）slave-read-only yes #从服务只读，不可在命令行写入数据5.0.4以后：replicaof &lt;masterip&gt; &lt;masterport&gt;replica-read-only yes 2. 重新启动从服务即实现主从连接121. ./bin/redis-cli # 启动redis客户端2. 输入 info replication # 查看与复制相关的状态，了解主从节点的当前状态 输入info replication 后显示的内容： 12345678910111213141516171819# Replicationrole:slave # 表示此台服务器是主是从master_host:39.107.38.62 # 主服务器ipmaster_port:6379 # 主服务器端口号master_link_status:up # 与主服务器是否连接成功 up为成功 down失败master_last_io_seconds_ago:9master_sync_in_progress:0slave_repl_offset:808slave_priority:100slave_read_only:1connected_slaves:0master_replid:ea5230cc485f9c6f372b2c89a65613fb075aff8bmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:808second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:15repl_backlog_histlen:794 遇到的报错：1. Error condition on socket for SYNC: Connection refused 出现原因：redis主服务器绑定了127.0.0.1，跨服务器IP的访问就会失败，只能本机才能访问，外部请求会被过滤。 1234解决方法：1. 主服务器绑定ip: bind 39.107.38.623. bind 0.0.0.02. 注释bind # 会报下面的错↓ 2. ‘-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connec 出现原因：处于保护模式，只能本地链接。没有绑定ip 没有设置验证密码。 123解决方法：1. 主服务器绑定ip： bind 39.107.38.622. 设置主服务器访问密码：requirepass 12345 3. (error) READONLY You can’t write against a read only replica.​ 出现原因：从库只可读不可写 12解决方法：1. 设置slave-read-only no # 代表不限于只读 断开主从复制​ 通过 slaveof 命令建立主从复制关系以后，可以通过slaveof no one断开。 从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"}]},{"title":"Redis的安装","slug":"Redis的安装","date":"2019-05-01T16:00:00.000Z","updated":"2019-12-27T12:43:13.002Z","comments":true,"path":"2019/05/02/Redis的安装/","link":"","permalink":"http://yoursite.com/2019/05/02/Redis%E7%9A%84%E5%AE%89%E8%A3%85/","excerpt":"","text":"1. 安装gcc redis是c语言编写的 1yum install gcc-c++ 2. 下载redis安装包,在root目录下执行1wget http://download.redis.io/releases/redis-5.0.4.tar.gz 3. 解压redis安装包1tar -zxvf redis-5.0.4.tar.gz #解压gz属性的压缩包 4. 进入redis目录1cd redis-5.0.4 5. 编译1make 6. 安装1make PREFIX=/usr/local/redis install 7. 拷贝redis.conf到安装目录1cp redis.conf /usr/local/redis 8. 进入 /usr/local/redis目录1cd /usr/local/redis/ 9. 编辑redis.conf1234567891011121314151617vim redis.conf1.后台启动，daemonize yes2.绑定端口，port 6379 默认是6379 需要安全组开放端口3.绑定IP，bind 192.168.2.1284.指定数据存放路径，dir /usr/local/redis/log rdb存放的路径5.指定持久化方式，appendonly yes6.requirepass redis129 设置密码7.指定日志存储地址, logfile &quot;/usr/local/redis/log/redis_run.log&quot;# 不指定日志将会被发送到/dev/null 10. 前端启动-无法部署集群1./bin/redis-server 11. 后端启动redis：1./bin/redis-server ./redis.conf 12. 查看是否启动成功：1ps aux | grep redis 13. 进入客户端1./bin/redis-cli --raw 处理中文乱码问题 14. 关闭redis进程121. 进入客户端 ./bin/redis-cli2. 输入 shutdown 15. 卸载redis1yum remove redis","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"}]},{"title":"git上传文件到gitee","slug":"git上传文件到gitee","date":"2019-02-05T16:00:00.000Z","updated":"2019-12-27T12:40:11.625Z","comments":true,"path":"2019/02/06/git上传文件到gitee/","link":"","permalink":"http://yoursite.com/2019/02/06/git%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0gitee/","excerpt":"","text":"在本地项目文件中使用 123git config --global user.name &quot;你的名字&quot;git config --global user.email &quot;你的邮箱&quot; 1. 初始化 123git init git remote add origin https://gitee.com/xxx/xxx.git (你的远程项目地址) 2. 克隆一下 1git clone https://****.git (你的远程项目地址) 3. 提交 1234567git pull origin mastergit add .git commit -m &quot;提交备注&quot;git push origin master push Vue项目时 要用强制推送： 1git push -f origin master","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://yoursite.com/tags/Git/"}]},{"title":"Python字典底层","slug":"Python字典底层","date":"2019-01-18T16:00:00.000Z","updated":"2019-12-27T12:40:50.382Z","comments":true,"path":"2019/01/19/Python字典底层/","link":"","permalink":"http://yoursite.com/2019/01/19/Python%E5%AD%97%E5%85%B8%E5%BA%95%E5%B1%82/","excerpt":"","text":"字典数据类型的hashmappython里的字典采用了哈希表，就像java里的HashMap，以键值对的方式存在并操作，最低能在 O(1)时间内完成搜索。 什么是哈希表： ​ 简单来说就是一张带索引和存储空间的表，对于任意可哈希对象，通过哈希索引的计算公式：hash(hashable)%k（对可哈希对象进行哈希计算，然后对结果进行取余运算），可将该对象映射为0到k-1之间的某个表索引，然后在该索引所对应的空间进行变量的存储/读取等操作。 哈希运算结果 取余运算结果 索引 键值对 hash(‘小王’)=2360347816510736229 2360347816510736229%3=0 0 ‘小王‘：26 hash(‘大熊’)=4284897975392025871 4284897975392025871%3=1 1 ‘大熊’：28 hash(‘牛牛’)=-7069010861127204901 -7069010861127204901%3=2 2 ‘牛牛’：3 其特点如下： 通过键来存取，而非偏移量; 键值对是无序的; 键和值可以是任意对象; 长度可变，任意嵌套; 在字典里，不能再有序列操作，虽然字典在某些方面与列表类似，但不要把列表套在字典上; Python字典如何运用哈希表： 我们通过描述插入，查询，删除，扩容，哈希碰撞这几个过程来解释这一切。 插入：对键进行哈希和取余运算，得到一个哈希表的索引，如果该索引所对应的表地址空间为空，将键值对存入该地址空间； 更新：对键进行哈希和取余运算，得到一个哈希表的索引，如果该索引所对应的地址空间中健与要更新的健一致，那么就更新该健所对应的值； 查询：对要查找的健进行哈希和取余运算，得到一个哈希表的索引，如果该索引所对应的地址空间中健与要查询的健一致，那么就将该键值对取出来； 扩容：字典初始化的时候，会对应初始化一个有k个空间的表，等空间不够用的时候，系统就会自动扩容，这时候会对已经存在的键值对重新进行哈希取余运算（重新进行插入操作）保存到其它位置； 碰撞：有时候对于不同的键，经过哈希取余运算之后，得到的索引值一样，这时采用公开寻址的方式，运用固定的模式将键值对插入到其它的地址空间，比如线性寻址：如果第i个位置已经被使用，我们就看看第i+1个，第i+2个，第i+3个有没有被使用…直到找到一个空间或者对空间进行扩容。 比如：我们想存储 {’小小‘：18}这个键值对，经过哈希和取余运算之后，我们发现，其对应的索引值是0，但是0所指向的空间已经被’小王‘占用了，这就是碰撞。怎么办呢？我们看看0+1对应的所以有没有被占用，如果没有，我们就把’小小‘放在索引1所对应的地址空间中。取的时候，也按照同样的规则，进行探查。 哈希运算 取余运算 索引值 键值对 hash(‘小王’)=2360347816510736229 2360347816510736229%3=0 0 ’小王‘：26 hash(‘小小’)=-2310146166101152587 -2310146166101152587%3=0 1 ’小小‘：18 注意： Cython 中 哈希表的计算公式为：hash(‘hashable’)&amp;k，其中k 为2的n次方减1，其实与hash(‘hashable’)%(k+1)的结果一致。 解决碰撞的方法，Python用的不是线性寻址，而是一种更为复杂的寻址模式。2","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"Mysql主从","slug":"Mysql主从","date":"2018-12-07T16:00:00.000Z","updated":"2019-12-27T12:37:19.368Z","comments":true,"path":"2018/12/08/Mysql主从/","link":"","permalink":"http://yoursite.com/2018/12/08/Mysql%E4%B8%BB%E4%BB%8E/","excerpt":"","text":"Mysql主从 什么是主从复制？ 主从复制至少需要两台服务器，或两个mysql服务，可以配置一主多从，多主多从 建立与某个业务数据库一样的数据库环境，即为主从复制 一般情况下，主库用以写，而从库用以读 Mysql主从原理： 利用数据库bin-log二进制文件，该文件包含有数据库操作的所有SQL语句 复制该文件至其余数据库服务中并执行即可。 从库建立IO线程连接主库主库响应连接开始线程，传输binlog 从库IO线程接收binlog写入relaylog 从库SQL线程，处理relaylog，写入db 主从复制过程： 当主库具有新数据时，主库会被从库请求，建立线程进行连接，用以传输binlog日志 从库开启两个线程： A线程：也叫做IO线程，连接主库，并请求binlog中的更新记录至从库中，写入至从库的relaylog文件中 B线程：也叫做SQL线程，读取relaylog文件中的更新操作并执行 如果，有多个从库同时存在，主库会为每个从库建立一个binlog输出线程 Mysql主从作用 构建主从热备，当某天数据库宕机或或数据丢失情况，可以有备份数据库继续工作 降低IO频次，多库之间可以合理分配读写压力，提高单个数据库服务的数据库访问压力 隔离读写，在某些锁表情况下，可以使数据库读操作继续进行 主机binlog日志： binlog日志存的二进制 增删改操作。 binlog存储地址：/var/lib/mysql/ 名为：mysql-bin.000001 binlog不能直接cat命令查看，需要用到mysql的日志管理工具： 12341. 查看mysql的主机binlog文件mysqlbinlog /var/lib/mysql/mysql-bin.0000012. mysqlbinlog /var/lib/mysql/mysql-bin.000001 | tail -n 10 # tail -n 10 表示查看末尾十行# head -n 10 表示查看开头十行 从机relay_log日志 relay_log中存储的需要同步的新的信息 Mysql主从配置 主机开启binlog日志 配置文件： 主机： 1234567891011121314151617[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.socksymbolic-links=0binlog_format=mixedserver-id = 1 # 用来表示数据库身份 类似pidlog-bin=mysql-bin # 开启binlog日志expire_logs_days=7general_log=1general_log_file=/var/lib/mysql/general.log[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid# include all files from the config directory!includedir /etc/my.cnf.d 从机： 123456789101112131415[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.socksymbolic-links=0binlog_format=mixedserver-id = 2 # 不能和主库一样# 从机不用开启log-bin功能expire_logs_days=7general_log=1general_log_file=/var/lib/mysql/general.log[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid 重启服务: 1systemctl restart mariadb 主库创建用户，用以从机连接获取binlog日志 12查看mysql内的所有用户：select user,host from mysql.user; 1234# 首先进入mysqlgrant replication slave on *.* to &apos;master&apos;@&apos;%&apos; identified by &apos;123456&apos;;# 创建了一个为从库工作的master用户，密码是123456，所对应的库*.*（所有的库）flush privileges; # 刷新权限 12grant all privileges on *.* to master@&apos;%&apos; identified by &quot;123456&quot;;# 为了保险起见，又给用户赋予了所有数据库的权限 查看master状态 12345678show master status;+------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+----------+--------------+------------------+| mysql-bin.000002 | 3755 | | |+------------------+----------+--------------+------------------+# File: binlog日志名称# Position: 从库从哪个位置开始同步 从库指定master 12345678change master to master_host=&apos;47.97.218.145&apos;, master_port=3306, master_user=&apos;master&apos;, master_password=&apos;123456&apos;, master_log_file=&apos;mysql-bin.000002&apos;, master_log_pos=3755;# master_hos： 主机ip地址# master_port：主机端口号# master_user：主机创建的用来连接从库的用户# master_password：主机数据库密码# master_log_file: 使用show master status;命令查出的binlog日志名称# master_log_pos: 使用show master status;命令查出的同步位置 当你上一条命令配置出错时，可以重置slave状态： 1reset slave all; 连接主从： 1start slave; 查看从机状态： 123456789101112131415161718192021222324252627282930313233343536373839404142show slave status \\G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 47.97.218.145 # 主机ip Master_User: master # 连接主从用户名 Master_Port: 3306 # 主机端口号 Connect_Retry: 60 Master_Log_File: mysql-bin.000003 # 同步的主机binlog Read_Master_Log_Pos: 245 # 同步起点 Relay_Log_File: mariadb-relay-bin.000005 # 从机relaylog名称 Relay_Log_Pos: 529 Relay_Master_Log_File: mysql-bin.000003 Slave_IO_Running: Yes # yes为链接成功 Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 245 Relay_Log_Space: 868 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 停止从库状态： 1stop slave; 主从需要注意的事项： mysqldump 如果从机断了，主库在疯狂增删改，从机过了一阵又启动了，重启回复从库状态 如果主机断了，写入直接进制了，此时用户想写，怎么能暂时吧从机变为可写的主机 一主多从 主从延迟，主从数据库尽量在同一局域网下，网速更快，服务器性能更好，磁盘要好 从库没必要开binlog就不开了","categories":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/tags/Mysql/"}]},{"title":"python算法","slug":"python算法","date":"2018-11-19T16:00:00.000Z","updated":"2019-12-27T12:38:22.297Z","comments":true,"path":"2018/11/20/python算法/","link":"","permalink":"http://yoursite.com/2018/11/20/python%E7%AE%97%E6%B3%95/","excerpt":"","text":"单链表反转12345678910111213141516171819202122232425262728293031323334#递归实现单链表反转class ListNode(object): def __init__(self,x): self.val=x self.next=Nonedef recurse(head,newhead): #递归，head为原链表的头结点，newhead为反转后链表的头结点 if head is None: return if head.next is None: newhead=head else : newhead=recurse(head.next,newhead) head.next.next=head head.next=None return newhead if __name__ == '__main__': head=ListNode(1) #测试代码 p1=ListNode(2) # 建立链表1-&gt;2-&gt;3-&gt;4-&gt;None p2=ListNode(3) p3=ListNode(4) head.next=p1 p1.next=p2 p2.next=p3 newhead=None p=recurse(head,newhead) #输出链表4-&gt;3-&gt;2-&gt;1-&gt;None while p: print(p.val) p=p.next 艾氏筛法求质数1234567891011121314151617181920import itertoolsdef _odd_iter(): n =1 # while True: # n = n+2 # yield n return itertools.count(3,2)def not_divisable(n): return lambda x:x %n&gt;0def primes(): yield 2 it = _odd_iter() while True: n = next(it) yield n it = filter(not_divisable(n),it)p = primes()for t in range(10): print(next(p)) 冒泡排序：123456789def bubble_sort(blist): count = len(blist) for i in range(0, count): for j in range(i + 1, count): if blist[i] &gt; blist[j]: blist[i], blist[j] = blist[j], blist[i] return blist blist = bubble_sort([4,5,6,7,3,2,6,9,8]) print(blist) 快排：1234567891011121314151617def quicksort(array): if len(array) &lt; 2: return array else: pivot = array[0] #找到一个基准值 #遍历整个列表，将小于这个基准值的元素放到一个子列表中 less = [i for i in array[1:] if i &lt; pivot] #遍历整个列表，将大于这个基准值的元素放到一个子列表中 greater = [i for i in array[1:] if i&gt;pivot] #首先，明确我们对元素为0个/1个的列表无需要排序 #使用函数递归 #目标：让我们在一个基准值的一侧变为有序，然后依次返回，让我们的每个基准值的两侧都变得有序 return quicksort(less)+[pivot]+quicksort(greater)#这是一些测试样例print(quicksort([2,5,3,9,7,11]))print(quicksort([152,134,38796,7438415,1,2272,34345,24,127])) 杨氏矩阵查找在一个m行n列二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 使用Step-wise线性搜索。 1234567891011121314151617def get_value(l, r, c): return l[r][c]def find(l, x): m = len(l) - 1 n = len(l[0]) - 1 r = 0 c = n while c &gt;= 0 and r &lt;= m: value = get_value(l, r, c) if value == x: return True elif value &gt; x: c = c - 1 elif value &lt; x: r = r + 1 return False 矩形覆盖我们可以用2*1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？ 第2*n个矩形的覆盖方法等于第2*(n-1)加上第2*(n-2)的方法。 1f = lambda n: 1 if n &lt; 2 else f(n - 1) + f(n - 2) 单例:123456789101112class Single(object): _instance = None def __new__(cls, *args, **kw): if cls._instance is None: cls._instance = object.__new__(cls, *args, **kw) return cls._instance def __init__(self): passsingle1 = Single()single2 = Single()print(id(single1) , id(single2)) 递归斐波那契：1234567891011def fun(i): if i == 0: return 0 elif i == 1: return 1 else: return fun(i-2) + fun(i-1)if __name__ == '__main__': for i in range(10): print(fun(i),end=\" \") 递归遍历目录：123456789import osdef get_dir(path,level=1): for file in os.listdir(path): file_path = os.path.join(path,file) print('-' * level,file) if os.path.isdir(file_path): get_dir(file_path, level + 1)get_dir(r'path') 闭包：1234567891011121314'''闭包的定义：在一个外函数中定义了一个内函数内函数里运用了外函数的临时变量并且外函数的返回值是内函数的引用。这样就构成了一个闭包。'''def outer(): a = 10 def innter(): b = a + 10 print(\"b =\",b) return innerouter()() 装饰器测试程序运行时间：123456789101112131415161718192021# 使用装饰器测试（1000以内的三个数，相加等于1000的情况，有多少组）这个案例的运行时间import timedef time_(fun): def inner(): s_time = time.time() #获取程序运行的开始时间 fun() #运行程序 e_time = time.time() #获取程序运行的结束时间 return e_time-s_time return inner @time_def func(): for a in range(1001): for b in range(1001): c = 1000 - a - b if a ** 2 + b ** 2 == c ** 2: print(\"a = %d , b = %d , c = %d\" % (a,b,c) if __name__ == '__main__': print(func()) python实现树，实现前中后遍历和层次遍历12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class Node(object): '''树的节点''' def __init__(self, item): self.elem = item self.lchild = None #左孩子 self.rchild = None #右孩子class Tree(object): '''二叉树''' def __init__(self): self.root = None # 根节点 def add(self,item): '''添加的方法''' node = Node(item) # 先构造一个节点 if self.root is None: # 如果是空树 直接添加元素 self.root = node return queue = [self.root] # 一个队列 用来存放的就是要遍历和处理的元素 while queue: #队列只要不为空 就始终能拿出节点进行判断 # 先从队列中取出一个节点 cur_node = queue.pop(0) # 看当前这个节点左边的孩子是否为空 如果是空 直接挂节点 if cur_node.lchild is None: cur_node.lchild = node return else: # 不为空则认定左孩子存在 追加到队列 queue.append(cur_node.lchild) # 查看节点右孩子 与左孩子同理 if cur_node.rchild is None: cur_node.rchild = node return else: queue.append(cur_node.rchild) def breadth_trvael(self): '''层次遍历''' if self.root == None: return queue = [self.root] while queue: # 只要队列不为空就一直取元素 cur_node = queue.pop(0) print(cur_node.elem,end=' ') # 如果左孩子存在 添加到队列中 if cur_node.lchild: queue.append(cur_node.lchild) # 右孩子同理 if cur_node.rchild: queue.append(cur_node.rchild) def preorder(self, node): #传一个根节点 '''先序遍历''' if node == None: #递归的终结条件 return print(node.elem,end=' ') #先打印根 self.preorder(node.lchild) #处理左半部分 self.preorder(node.rchild) #处理右半部分 def inorder(self, node): '''中序遍历''' if node == None: return self.inorder(node.lchild) # 先处理左部分 print(node.elem, end=' ') #输出根 self.inorder(node.rchild) #再处理右半部分 def postorder(self, node): '''后序遍历''' if node == None: return self.postorder(node.lchild) # 先处理左部分 self.postorder(node.rchild) # 然后处理右半部分 print(node.elem, end=' ') # 最后输出根if __name__ == '__main__': tree = Tree() # 添加元素 tree.add(0) tree.add(1) tree.add(2) tree.add(3) tree.add(4) print('层次遍历：') tree.breadth_trvael() print('\\n') print('先序遍历：') tree.preorder(tree.root) print('\\n') print('中序遍历：') tree.inorder(tree.root) print('\\n') print('后序遍历：') tree.postorder(tree.root) print('\\n') 实现单向链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112class Node(object): '''节点类''' def __init__(self,elem): self.elem = elem self.next = Noneclass SingleLinkList(object): '''单链表''' def __init__(self, node=None): self.head = node def is_empty(self): '''判断链表是否为空''' return self.head == None #如果头节点为空 列表就为空 def length(self): '''链表长度''' cur = self.head #cur游标 用来移动遍历节点 count = 0 #记录数量 while cur != None: count += 1 cur = cur.next #移动游标 return count def travel(self): '''遍历整个链表''' cur = self.head #代表第一个节点 while cur != None: print(cur.elem) cur = cur.next def add(self, item): '''在链表头部添加元素，头插法''' node = Node(item) node.next = self.head # 新元素的下一个节点指向链表第一个元素 self.head = node #头节点指向新元素 def append(self, item): '''向链表的尾部添加元素,尾插法''' node = Node(item) if self.is_empty(): #如果链表为空 self.head = node #头节点指向添加的元素 else: #不为空 cur = self.head # 游标 while cur.next != None: # 游标下一个位置不为空开始进入循环 为空则不进入循环 cur = cur.next # 游标移动 cur.next = node #当游标下一位置为空时添加元素 def insert(self, pos, item): # 传入一个插入位置pos 一个插入元素item '''指定位置添加元素''' # 如果添加位置在头部 直接使用头插入方法 if pos &lt;= 0 : self.add(item) elif pos &gt; (self.length()-1): #插入位置超出列表范围 使用尾插法 self.append(item) else: cur = self.head count = 0 while count &lt; (pos-1): count += 1 cur = cur.next # 当循环退出后cur指向 pos-1位置 node = Node(item) node.next = cur.next cur.next = node def remove(self, item): '''删除元素,根据具体的数据删除''' cur = self.head pre = None # 前一位置 while cur != None: if cur.elem == item: # 先判断子节点是否为头节点 if cur == self.head: self.head = cur.next # 直接改变头指针指向的地址 else: pre.next = cur.next # 如果删除尾部 cur.next刚好指向none break else: pre = cur cur = cur.next def search(self, item): '''查找节点是否存在''' cur = self.head while cur != None: # 列表不为空时 if cur.elem == item: return True else: cur = cur.next return Falseif __name__ == '__main__': ll = SingleLinkList() print('是否为空:',ll.is_empty()) print('链表长度：',ll.length()) # 添加元素 ll.append(2) #尾部添加 ll.append(6) ll.add(8) #头部添加 ll.append(1) ll.insert(3,9) print('开始遍历链表元素：') ll.travel() # 删除一个元素 ll.remove(6) print('删除后遍历：') ll.travel() print('是否为空:',ll.is_empty()) print('链表长度：',ll.length()) print('元素是否存在：',ll.search(10)) print('元素是否存在：',ll.search(9)) 链表成对调换1-&gt;2-&gt;3-&gt;4转换成2-&gt;1-&gt;4-&gt;3. 123456789101112131415class ListNode: def __init__(self, x): self.val = x self.next = Noneclass Solution: # @param a ListNode # @return a ListNode def swapPairs(self, head): if head != None and head.next != None: next = head.next head.next = self.swapPairs(next.next) next.next = head return next return head 交叉链表求交点 其实思想可以按照从尾开始比较两个链表，如果相交，则从尾开始必然一致，只要从尾开始比较，直至不一致的地方即为交叉点 123456789101112131415161718192021222324252627282930#coding:utf-8class ListNode: def __init__(self, x): self.val = x self.next = Nonedef node(l1, l2): length1, length2 = 0, 0 # 求两个链表长度 while l1.next: l1 = l1.next#尾节点 length1 += 1 while l2.next: l2 = l2.next#尾节点 length2 += 1 #如果相交 if l1.next == l2.next: # 长的链表先走 if length1 &gt; length2: for _ in range(length1 - length2): l1 = l1.next return l1#返回交点 else: for _ in range(length2 - length1): l2 = l2.next return l2#返回交点 # 如果不相交 else: return 实现栈1234567891011121314151617181920212223242526272829303132333435363738394041424344454647\"\"\"Stack() 创建一个新的空栈push(item) 添加一个新的元素item到栈顶pop() 弹出栈顶元素peek() 返回栈顶元素is_empty() 判断栈是否为空size() 返回栈的元素个数\"\"\"class Stack(object): \"\"\"栈类\"\"\" def __init__(self): \"\"\"创建一个空栈\"\"\" self.stack = [] def push(self,item): \"\"\"添加一个新的元素到栈顶\"\"\" self.stack.append(item) def pop(self): \"\"\"弹出栈顶元素\"\"\" return self.stack.pop() def peek(self): \"\"\"返回栈顶元素\"\"\" return self.stack[-1] def is_empty(self): \"\"\"判断栈是否为空\"\"\" return self.stack == [] def size(self): \"\"\"返回栈元素的个数\"\"\" return len(self.stack)if __name__ == '__main__': s = Stack() print(s.is_empty()) #判断栈是否为空 print(s.size()) # 获取栈的大小 print(\"*\"*10) s.push(2) #添加元素 s.push(6) s.push(3) print(s.stack) #输出栈 print(s.pop()) #弹出栈顶元素 print(s.size()) #获取栈的大小 print(s.pop()) print(s.size()) print(s.pop()) print(s.size()) print(\"*\"*10) print(s.is_empty()) print(s.size()) 实现队列：123456789101112131415161718192021222324252627282930313233343536373839404142\"\"\"Queue() 创建一个空的队列enqueue(item) 往队列中添加一个item元素dequeue() 从队列头部删除一个元素is_empty() 判断一个队列是否为空size() 返回队列的大小\"\"\"class Queue(object): \"\"\"队列\"\"\" def __init__(self): \"\"\"创建一个空队列\"\"\" self.queue = [] def enqueue(self,item): \"\"\"往队列中添加一个元素\"\"\" self.queue.append(item) def dequeue(self): \"\"\"从队列头部删除一个元素\"\"\" return self.queue.pop(0) def ie_empty(self): \"\"\"判断一个队列是否为空\"\"\" return self.queue == [] def size(self): \"\"\"返回队列大小\"\"\" return len(self.queue)if __name__ == '__main__': q = Queue() print(q.ie_empty()) print(q.size()) print(\"*\"*10) q.enqueue(5) q.enqueue(6) q.enqueue(7) print(q.dequeue()) print(q.size()) print(\"*\"*10) print(q.dequeue()) print(q.size()) print(\"*\"*10) print(q.dequeue()) print(q.ie_empty()) print(q.size()) 不用循环和条件打印1~1000123456import syssys.setrecursionlimit(1005)def printnum(n): print(n) return (n-1000) and printnum(n+1)printnum(1) 找零问题123456789101112131415161718#coding:utf-8#values是硬币的面值values = [ 25, 21, 10, 5, 1]#valuesCounts 钱币对应的种类数#money 找出来的总钱数#coinsUsed 对应于目前钱币总数i所使用的硬币数目def coinChange(values,valuesCounts,money,coinsUsed): #遍历出从1到money所有的钱数可能 for cents in range(1,money+1): minCoins = cents #把所有的硬币面值遍历出来和钱数做对比 for kind in range(0,valuesCounts): if (values[kind] &lt;= cents): temp = coinsUsed[cents - values[kind]] +1 if (temp &lt; minCoins): minCoins = temp coinsUsed[cents] = minCoins print ('面值:&#123;0&#125;的最少硬币使用数为:&#123;1&#125;'.format(cents, coinsUsed[cents])) 二分查找12345678910111213141516#coding:utf-8def binary_search(list, item): low = 0 high = len(list) - 1 while low &lt;= high: mid = (high - low) / 2 + low # 避免(high + low) / 2溢出 guess = list[mid] if guess &gt; item: high = mid - 1 elif guess &lt; item: low = mid + 1 else: return mid return Nonemylist = [1,3,5,7,9]print binary_search(mylist, 3) 去除列表中的重复元素用集合12my_list = [1,2,1,1,4,3,2,2,5,6,6,6]print(list(set(my_list))) 用字典123l1 = ['b','c','d','b','c','a','a']l2 = &#123;&#125;.fromkeys(l1).keys()print l2 用字典并保持顺序1234l1 = ['b','c','d','b','c','a','a']l2 = list(set(l1))l2.sort(key=l1.index)print l2 列表推导式123l1 = ['b','c','d','b','c','a','a']l2 = [][l2.append(i) for i in l1 if not i in l2] sorted排序并且用列表推导式.1l = ['b','c','d','b','c','a','a'][single.append(i) for i in sorted(l) if i not in single] print single 青蛙跳台阶递归1234567891011def leap_frog(step): if step &lt; 1: return \"输入错误\" if step == 1 or step == 2: return step else: return leap_frog(step-1) + leap_frog(step-2)if __name__ == '__main__': print(leap_frog(5)) 变态台阶问题一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。 1fib = lambda n: n if n &lt; 2 else 2 * fib(n - 1) 插入排序插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的、个数加一的有序数据，算法适用于少量数据的排序；首先将第一个作为已经排好序的，然后每次从后的取出插入到前面并排序； 1234567891011# 时间复杂度：O(n²)# 空间复杂度：O(1)# 稳定性：稳定def insert_sort(ilist): for i in range(len(ilist)): for j in range(i): if ilist[i] &lt; ilist[j]: ilist.insert(j, ilist.pop(i)) break return ilist 选择排序第1趟，在待排序记录r1 ~ r[n]中选出最小的记录，将它与r1交换； 第2趟，在待排序记录r2 ~ r[n]中选出最小的记录，将它与r2交换； 以此类推，第i趟在待排序记录r[i] ~ r[n]中选出最小的记录，将它与r[i]交换，使有序序列不断增长直到全部排序完毕 1234567891011121314# 时间复杂度：O(n²)# 空间复杂度：O(1)# 稳定性：不稳定def select_sort(slist): for i in range(len(slist)): x = i for j in range(i, len(slist)): if slist[j] &lt; slist[x]: x = j slist[i], slist[x] = slist[x], slist[i] return slistslist = select_sort([4,5,6,7,3,2,6,9,8]) 归并排序采用分治法（Divide and Conquer）的一个非常典型的应用。 将已有序的子序列合并，得到完全有序的序列； 即先使每个子序列有序，再使子序列段间有序。 若将两个有序表合并成一个有序表，称为二路归并. 123456789101112131415161718192021222324252627# 时间复杂度：O(nlog₂n)# 空间复杂度：O(1)# 稳定性：稳定def merge_sort(array): def merge_arr(arr_l, arr_r): array = [] while len(arr_l) and len(arr_r): if arr_l[0] &lt;= arr_r[0]: array.append(arr_l.pop(0)) elif arr_l[0] &gt; arr_r[0]: array.append(arr_r.pop(0)) if len(arr_l) != 0: array += arr_l elif len(arr_r) != 0: array += arr_r return array def recursive(array): if len(array) == 1: return array mid = len(array) // 2 arr_l = recursive(array[:mid]) arr_r = recursive(array[mid:]) return merge_arr(arr_l, arr_r) return recursive(array)","categories":[{"name":"Python算法题","slug":"Python算法题","permalink":"http://yoursite.com/categories/Python%E7%AE%97%E6%B3%95%E9%A2%98/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"Python","slug":"Python","date":"2018-11-12T16:00:00.000Z","updated":"2019-12-27T12:37:49.002Z","comments":true,"path":"2018/11/13/Python/","link":"","permalink":"http://yoursite.com/2018/11/13/Python/","excerpt":"","text":"冒泡排序：它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。 时间复杂度：O(n²)空间复杂度：O(1)稳定性：稳定 12345678910def bubble_sort(blist): count = len(blist) for i in range(0, count): for j in range(i + 1, count): if blist[i] &gt; blist[j]: blist[i], blist[j] = blist[j], blist[i] return blistblist = bubble_sort([4,5,6,7,3,2,6,9,8])print(blist) 快排：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 时间复杂度：O(nlog₂n)空间复杂度：O(nlog₂n)稳定性：不稳定 12345678910111213141516171819#O(n*(log n))def quicksort(array): if len(array) &lt; 2: return array else: pivot = array[0] #找到一个基准值 #遍历整个列表，将小于这个基准值的元素放到一个子列表中 less = [i for i in array[1:] if i &lt; pivot] #遍历整个列表，将大于这个基准值的元素放到一个子列表中 greater = [i for i in array[1:] if i&gt;pivot] #首先，明确我们对元素为0个/1个的列表无需要排序 #使用函数递归 #目标：让我们在一个基准值的一侧变为有序，然后依次返回，让我们的每个基准值的两侧都变得有序 return quicksort(less)+[pivot]+quicksort(greater)#这是一些测试样例print(quicksort([2,5,3,9,7,11]))print(quicksort([152,134,38796,7438415,1,2272,34345,24,127])) 单例：保证一个类只有一个实例，并提供一个访问它的全局访问点 优点：对唯一实例的受控访问，相当于全局变量，但是又可以防止变量被篡改 通过new方法，将类的实例在创建的时候绑定到类属性_inst上。如果cls._inst为None，说明类还未实例化，实例化并将实例绑定到cls._inst，以后每次实例化的时候都返回第一次实例化创建的实例。注意从Singleton派生子类的时候，不要重载new。因为类每一次实例化后产生的过程都是通过new来控制的，所以通过重载new方法，我们 可以很简单的实现单例模式。 123456789101112class Single(object): _instance = None def __new__(cls, *args, **kw): if cls._instance is None: cls._instance = object.__new__(cls, *args, **kw) return cls._instance def __init__(self): passsingle1 = Single()single2 = Single()print(id(single1) , id(single2)) _ _ new _ _方法:使用类名()创建对象时，Python的解释器首先会调用new方法为对象分配空间._ _ new _ _是一个有object基类提供的内置的静态方法，主要作用有两个： 在内存中为对象分配空间 返回对象的引用Python的解释器获得对象的引用后，将引用作为第一个参数，传递给init方法。重写new方法的代码非常固定。重写new方法一定要return super.new(cls)，否则Python的解释器得不到分配了空间的对象引用，就不会调用对象的初始化方法注意：new是一个静态方法，在调用时需要主动传递参数clsnew至少要有一个参数cls，代表要实例化的类，此参数在实例化时由Python解释器自动提供 递归斐波那契数列：1234567891011def fun(i): if i == 0: return 0 elif i == 1: return 1 else: return fun(i-2) + fei(i-1)if __name__ == '__main__': for i in range(10): print(fun(i),end=\" \") 递归遍历目录：123456789101112131415import osdef fun(p): for i in os.listdir(p): i = os.path.join(p,i) if os.path.isdir(i): return fun(i) if os.path.splitext(i)[1] == '.txt': print i else: return fun(i)path = unicode(r'F:\\My Study\\linux学习笔记\\test','utf-8') #需要遍历的目录f(path) 青蛙跳台阶参考链接：https://blog.csdn.net/Bryce_Liu/article/details/90639516 闭包：闭包的定义： 在一个外函数中定义了一个内函数 内函数里运用了外函数的临时变量 并且外函数的返回值是内函数的引用。这样就构成了一个闭包。 12345678def outer(): a = 10 def inner(): b = a + 10 print(\"b =\",b) return innerouter()() 装饰器测试程序运行时间： 使用装饰器测试（1000以内的三个数，相加等于1000的情况，有多少组）这个案例的运行时间 1234567891011121314151617181920import timedef time_(fun): def inner(): s_time = time.time() #获取程序运行的开始时间 fun() #运行程序 e_time = time.time() #获取程序运行的结束时间 return e_time-s_time return inner @time_def func(): for a in range(1001): for b in range(1001): c = 1000 - a - b if a ** 2 + b ** 2 == c ** 2: print(\"a = %d , b = %d , c = %d\" % (a,b,c) if __name__ == '__main__': print(func()) python实现树的遍历：参考链接：https://blog.csdn.net/bone_ace/article/details/46718683 广度遍历：层次遍历深度遍历：先、中、后序遍历 层次遍历：一层一层的遍历先序遍历：依据 根–左–右 的顺序遍历中序遍历：依据 左–根–右 的顺序遍历后序遍历：依据 左–右–根 的顺序遍历 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102class Node(object): '''树的节点''' def __init__(self, item): self.elem = item self.lchild = None #左孩子 self.rchild = None #右孩子class Tree(object): '''二叉树''' def __init__(self): self.root = None # 根节点 def add(self,item): '''添加的方法''' node = Node(item) # 先构造一个节点 if self.root is None: # 如果是空树 直接添加元素 self.root = node return queue = [self.root] # 一个队列 用来存放的就是要遍历和处理的元素 while queue: #队列只要不为空 就始终能拿出节点进行判断 # 先从队列中取出一个节点 cur_node = queue.pop(0) # 看当前这个节点左边的孩子是否为空 如果是空 直接挂节点 if cur_node.lchild is None: cur_node.lchild = node return else: # 不为空则认定左孩子存在 追加到队列 queue.append(cur_node.lchild) # 查看节点右孩子 与左孩子同理 if cur_node.rchild is None: cur_node.rchild = node return else: queue.append(cur_node.rchild) def breadth_trvael(self): '''层次遍历''' if self.root == None: return queue = [self.root] while queue: # 只要队列不为空就一直取元素 cur_node = queue.pop(0) print(cur_node.elem,end=' ') # 如果左孩子存在 添加到队列中 if cur_node.lchild: queue.append(cur_node.lchild) # 右孩子同理 if cur_node.rchild: queue.append(cur_node.rchild) def preorder(self, node): #传一个根节点 '''先序遍历''' if node == None: #递归的终结条件 return print(node.elem,end=' ') #先打印根 self.preorder(node.lchild) #处理左半部分 self.preorder(node.rchild) #处理右半部分 def inorder(self, node): '''中序遍历''' if node == None: return self.inorder(node.lchild) # 先处理左部分 print(node.elem, end=' ') #输出根 self.inorder(node.rchild) #再处理右半部分 def postorder(self, node): '''后序遍历''' if node == None: return self.postorder(node.lchild) # 先处理左部分 self.postorder(node.rchild) # 然后处理右半部分 print(node.elem, end=' ') # 最后输出根if __name__ == '__main__': tree = Tree() # 添加元素 tree.add(0) tree.add(1) tree.add(2) tree.add(3) tree.add(4) tree.add(5) tree.add(6) tree.add(7) tree.add(8) tree.add(9) print('层次遍历：') tree.breadth_trvael() print('\\n') print('先序遍历：') tree.preorder(tree.root) print('\\n') print('中序遍历：') tree.inorder(tree.root) print('\\n') print('后序遍历：') tree.postorder(tree.root) print('\\n') 链表：参考链接：https://www.jianshu.com/p/9f2aca048c84https://www.jb51.net/article/133798.htm 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112class Node(object): '''节点类''' def __init__(self,elem): self.elem = elem self.next = Noneclass SingleLinkList(object): '''单链表''' def __init__(self, node=None): self.head = node def is_empty(self): '''判断链表是否为空''' return self.head == None #如果头节点为空 列表就为空 def length(self): '''链表长度''' cur = self.head #cur游标 用来移动遍历节点 count = 0 #记录数量 while cur != None: count += 1 cur = cur.next #移动游标 return count def travel(self): '''遍历整个链表''' cur = self.head #代表第一个节点 while cur != None: print(cur.elem) cur = cur.next def add(self, item): '''在链表头部添加元素，头插法''' node = Node(item) node.next = self.head # 新元素的下一个节点指向链表第一个元素 self.head = node #头节点指向新元素 def append(self, item): '''向链表的尾部添加元素,尾插法''' node = Node(item) if self.is_empty(): #如果链表为空 self.head = node #头节点指向添加的元素 else: #不为空 cur = self.head # 游标 while cur.next != None: # 游标下一个位置不为空开始进入循环 为空则不进入循环 cur = cur.next # 游标移动 cur.next = node #当游标下一位置为空时添加元素 def insert(self, pos, item): # 传入一个插入位置pos 一个插入元素item '''指定位置添加元素''' # 如果添加位置在头部 直接使用头插入方法 if pos &lt;= 0 : self.add(item) elif pos &gt; (self.length()-1): #插入位置超出列表范围 使用尾插法 self.append(item) else: cur = self.head count = 0 while count &lt; (pos-1): count += 1 cur = cur.next # 当循环退出后cur指向 pos-1位置 node = Node(item) node.next = cur.next cur.next = node def remove(self, item): '''删除元素,根据具体的数据删除''' cur = self.head pre = None # 前一位置 while cur != None: if cur.elem == item: # 先判断子节点是否为头节点 if cur == self.head: self.head = cur.next # 直接改变头指针指向的地址 else: pre.next = cur.next # 如果删除尾部 cur.next刚好指向none break else: pre = cur cur = cur.next def search(self, item): '''查找节点是否存在''' cur = self.head while cur != None: # 列表不为空时 if cur.elem == item: return True else: cur = cur.next return Falseif __name__ == '__main__': ll = SingleLinkList() print('是否为空:',ll.is_empty()) print('链表长度：',ll.length()) # 添加元素 ll.append(2) #尾部添加 ll.append(6) ll.add(8) #头部添加 ll.append(1) ll.insert(3,9) print('开始遍历链表元素：') ll.travel() # 删除一个元素 ll.remove(6) print('删除后遍历：') ll.travel() print('是否为空:',ll.is_empty()) print('链表长度：',ll.length()) print('元素是否存在：',ll.search(10)) print('元素是否存在：',ll.search(9)) 栈与队列：参考链接：https://blog.csdn.net/yushupan/article/details/82312819https://www.jianshu.com/p/1327cc0de255 栈和队列是两种基本的数据结构，同为容器类型。 两者根本的区别在于： 栈stack:后进先出 队列queue:先进先出 栈的构造：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647\"\"\"Stack() 创建一个新的空栈push(item) 添加一个新的元素item到栈顶pop() 弹出栈顶元素peek() 返回栈顶元素is_empty() 判断栈是否为空size() 返回栈的元素个数\"\"\"class Stack(object): \"\"\"栈类\"\"\" def __init__(self): \"\"\"创建一个空栈\"\"\" self.stack = [] def push(self,item): \"\"\"添加一个新的元素到栈顶\"\"\" self.stack.append(item) def pop(self): \"\"\"弹出栈顶元素\"\"\" return self.stack.pop() def peek(self): \"\"\"返回栈顶元素\"\"\" return self.stack[-1] def is_empty(self): \"\"\"判断栈是否为空\"\"\" return self.stack == [] def size(self): \"\"\"返回栈元素的个数\"\"\" return len(self.stack)if __name__ == '__main__': s = Stack() print(s.is_empty()) print(s.size()) print(\"*\"*10) s.push(2) s.push(6) s.push(3) print(s.stack) print(s.pop()) print(s.size()) print(s.pop()) print(s.size()) print(s.pop()) print(s.size()) print(\"*\"*10) print(s.is_empty()) print(s.size()) 队列的构造：123456789101112131415161718192021222324252627282930313233343536373839404142\"\"\"Queue() 创建一个空的队列enqueue(item) 往队列中添加一个item元素dequeue() 从队列头部删除一个元素is_empty() 判断一个队列是否为空size() 返回队列的大小\"\"\"class Queue(object): \"\"\"队列\"\"\" def __init__(self): \"\"\"创建一个空队列\"\"\" self.queue = [] def enqueue(self,item): \"\"\"往队列中添加一个元素\"\"\" self.queue.append(item) def dequeue(self): \"\"\"从队列头部删除一个元素\"\"\" return self.queue.pop(0) def ie_empty(self): \"\"\"判断一个队列是否为空\"\"\" return self.queue == [] def size(self): \"\"\"返回队列大小\"\"\" return len(self.queue)if __name__ == '__main__': q = Queue() print(q.ie_empty()) print(q.size()) print(\"*\"*10) q.enqueue(5) q.enqueue(6) q.enqueue(7) print(q.dequeue()) print(q.size()) print(\"*\"*10) print(q.dequeue()) print(q.size()) print(\"*\"*10) print(q.dequeue()) print(q.ie_empty()) print(q.size())","categories":[{"name":"Python算法题","slug":"Python算法题","permalink":"http://yoursite.com/categories/Python%E7%AE%97%E6%B3%95%E9%A2%98/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]}]}